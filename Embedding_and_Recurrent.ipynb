{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOqSMmpzy2s2bylgP4A2Ft3",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/GrainSack/GrainSack/blob/main/Embedding_and_Recurrent.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Embedding\n",
        "\n"
      ],
      "metadata": {
        "id": "gGYZlarravy5"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y76wShMBSxsd",
        "outputId": "65f09af8-d3c5-4bdb-91ce-0d1aa554a7bb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[1. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [1. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [1. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [1. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 1. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 1. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 1. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 1. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 1. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 1. 0. 0. 0.]]\n"
          ]
        }
      ],
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "vocab = {      # 사용할 단어 사전 정의\n",
        "    \"i\": 0,\n",
        "    \"need\": 1,\n",
        "    \"some\": 2,\n",
        "    \"more\": 3,\n",
        "    \"coffee\": 4,\n",
        "    \"cake\": 5,\n",
        "    \"cat\": 6,\n",
        "    \"dog\": 7\n",
        "}\n",
        "\n",
        "sentence = \"i i i i need some more coffee coffee coffee\"\n",
        "# 위 sentence\n",
        "_input = [vocab[w] for w in sentence.split()]  # [0, 0, 0, 0, 1, 2, 3, 4, 4, 4]\n",
        "\n",
        "vocab_size = len(vocab)   # 8\n",
        "\n",
        "one_hot = tf.one_hot(_input, vocab_size)\n",
        "print(one_hot.numpy())    # 원-핫 인코딩 벡터를 출력해 봅시다."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "distribution_size = 2   # 보기 좋게 2차원으로 분산 표현하도록 하죠!\n",
        "linear = tf.keras.layers.Dense(units=distribution_size, use_bias=False)\n",
        "#Make abstract structure\n",
        "one_hot_linear = linear(one_hot)\n",
        "#통과하고 나면 input에 맞는 weight가 만들어진다\n",
        "\n",
        "print(\"Linear Weight\")\n",
        "print(linear.weights[0].numpy())\n",
        "\n",
        "print(\"\\nOne-Hot Linear Result\")\n",
        "print(one_hot_linear.numpy())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DMIa7WrfVm-h",
        "outputId": "0bb9c8e2-3f47-4a8e-c643-fae0d9d16e4c"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Linear Weight\n",
            "[[ 0.6747391  -0.47515717]\n",
            " [-0.71917826 -0.39267728]\n",
            " [ 0.5478486  -0.39411944]\n",
            " [-0.40606666 -0.07951248]\n",
            " [-0.34658936  0.36998463]\n",
            " [ 0.11903268  0.57018876]\n",
            " [-0.6102709   0.47502458]\n",
            " [-0.3167507  -0.58295035]]\n",
            "\n",
            "One-Hot Linear Result\n",
            "[[ 0.6747391  -0.47515717]\n",
            " [ 0.6747391  -0.47515717]\n",
            " [ 0.6747391  -0.47515717]\n",
            " [ 0.6747391  -0.47515717]\n",
            " [-0.71917826 -0.39267728]\n",
            " [ 0.5478486  -0.39411944]\n",
            " [-0.40606666 -0.07951248]\n",
            " [-0.34658936  0.36998463]\n",
            " [-0.34658936  0.36998463]\n",
            " [-0.34658936  0.36998463]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "some_words = tf.constant([[3, 57, 35]])\n",
        "# 3번 단어 / 57번 단어 / 35번 단어로 이루어진 한 문장입니다.\n",
        "\n",
        "print(\"Embedding을 진행할 문장:\", some_words.shape) \n",
        "embedding_layer = tf.keras.layers.Embedding(input_dim=64, output_dim=100)\n",
        "# 총 64개의 단어를 포함한 Embedding 레이어를 선언할 것이고,\n",
        "# 각 단어는 100차원으로 분산 표현 할 것입니다.\n",
        "\n",
        "print(\"Embedding된 문장:\", embedding_layer(some_words).shape)\n",
        "print(\"Embedding Layer의 Weight 형태:\", embedding_layer.weights[0].shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Zq7IxBJEV9ne",
        "outputId": "31663601-4440-4f7e-ea81-aec351486a0f"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Embedding을 진행할 문장: (1, 3)\n",
            "Embedding된 문장: (1, 3, 100)\n",
            "Embedding Layer의 Weight 형태: (64, 100)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#For 3 curpos is input e_3, thus whis compnents should be same\n",
        "print(embedding_layer.weights[0][3] == embedding_layer(some_words)[0][0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bLtIdjMYWP4e",
        "outputId": "d2d76b4e-a988-4ec9-8f51-9f3ff2dab312"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tf.Tensor(\n",
            "[ True  True  True  True  True  True  True  True  True  True  True  True\n",
            "  True  True  True  True  True  True  True  True  True  True  True  True\n",
            "  True  True  True  True  True  True  True  True  True  True  True  True\n",
            "  True  True  True  True  True  True  True  True  True  True  True  True\n",
            "  True  True  True  True  True  True  True  True  True  True  True  True\n",
            "  True  True  True  True  True  True  True  True  True  True  True  True\n",
            "  True  True  True  True  True  True  True  True  True  True  True  True\n",
            "  True  True  True  True  True  True  True  True  True  True  True  True\n",
            "  True  True  True  True], shape=(100,), dtype=bool)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# RNN"
      ],
      "metadata": {
        "id": "FGCODhoEYxa6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "sentence = \"What time is it ?\"\n",
        "dic = {\n",
        "    \"is\": 0,\n",
        "    \"it\": 1,\n",
        "    \"What\": 2,\n",
        "    \"time\": 3,\n",
        "    \"?\": 4\n",
        "}\n",
        "\n",
        "print(\"RNN에 입력할 문장:\", sentence)\n",
        "\n",
        "sentence_tensor = tf.constant([[dic[word] for word in sentence.split()]])\n",
        "\n",
        "print(\"Embedding을 위해 단어 매핑:\", sentence_tensor.numpy())\n",
        "print(\"입력 문장 데이터 형태:\", sentence_tensor.shape)\n",
        "\n",
        "embedding_layer = tf.keras.layers.Embedding(input_dim=len(dic), output_dim=100)\n",
        "emb_out = embedding_layer(sentence_tensor)\n",
        "\n",
        "print(\"\\nEmbedding 결과:\", emb_out.shape)\n",
        "print(\"Embedding Layer의 Weight 형태:\", embedding_layer.weights[0].shape)\n",
        "\n",
        "rnn_seq_layer = tf.keras.layers.SimpleRNN(units=64, return_sequences=True, use_bias=False)\n",
        "rnn_seq_out = rnn_seq_layer(emb_out)\n",
        "\n",
        "print(\"\\nRNN 결과 (모든 Step Output):\", rnn_seq_out.shape)\n",
        "print(\"RNN Layer의 Weight 형태:\", rnn_seq_layer.weights[0].shape)\n",
        "\n",
        "rnn_fin_layer = tf.keras.layers.SimpleRNN(units=64, use_bias=False)\n",
        "rnn_fin_out = rnn_fin_layer(emb_out)\n",
        "\n",
        "print(\"\\nRNN 결과 (최종 Step Output):\", rnn_fin_out.shape)\n",
        "print(\"RNN Layer의 Weight 형태:\", rnn_fin_layer.weights[0].shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nmV6XeDRWixr",
        "outputId": "9c5025eb-3311-41ad-cef1-b994ccee6f6d"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RNN에 입력할 문장: What time is it ?\n",
            "Embedding을 위해 단어 매핑: [[2 3 0 1 4]]\n",
            "입력 문장 데이터 형태: (1, 5)\n",
            "\n",
            "Embedding 결과: (1, 5, 100)\n",
            "Embedding Layer의 Weight 형태: (5, 100)\n",
            "\n",
            "RNN 결과 (모든 Step Output): (1, 5, 64)\n",
            "RNN Layer의 Weight 형태: (100, 64)\n",
            "\n",
            "RNN 결과 (최종 Step Output): (1, 64)\n",
            "RNN Layer의 Weight 형태: (100, 64)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "'''\n",
        "어떤 문장이 긍정인지 부정인지 나누기 위해서라면 문장을 모두 읽은 후, 최종 Step의 Output만 확인해도 판단이 가능합니다.\n",
        "하지만 문장을 생성하는 경우라면 이전 단어를 입력으로 받아 생성된 모든 다음 단어, 즉 모든 Step에 대한 Output이 필요하죠.\n",
        "그것은 위 코드에서 tf.keras.layers.SimpleRNN 레이어의 return_sequences 인자를 조절함으로써 조절할 수 있습니다!\n",
        "'''\n",
        "lstm_seq_layer = tf.keras.layers.LSTM(units=64, return_sequences=True, use_bias=False)\n",
        "lstm_seq_out = lstm_seq_layer(emb_out)\n",
        "\n",
        "print(\"\\nLSTM 결과 (모든 Step Output):\", lstm_seq_out.shape)\n",
        "print(\"LSTM Layer의 Weight 형태:\", lstm_seq_layer.weights[0].shape)\n",
        "\n",
        "lstm_fin_layer = tf.keras.layers.LSTM(units=64, use_bias=False)\n",
        "lstm_fin_out = lstm_fin_layer(emb_out)\n",
        "\n",
        "print(\"\\nLSTM 결과 (최종 Step Output):\", lstm_fin_out.shape)\n",
        "print(\"LSTM Layer의 Weight 형태:\", lstm_fin_layer.weights[0].shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F1zr-ye3WkPv",
        "outputId": "f672bcb4-1a28-4359-dc56-3d2bfe06bd53"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "LSTM 결과 (모든 Step Output): (1, 5, 64)\n",
            "LSTM Layer의 Weight 형태: (100, 256)\n",
            "\n",
            "LSTM 결과 (최종 Step Output): (1, 64)\n",
            "LSTM Layer의 Weight 형태: (100, 256)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Lstm and GRU is robust for long term dependency\n",
        "- Theorical basic\\\n",
        "https://curt-park.github.io/2017-04-03/why-is-lstm-strong-on-gradient-vanishing/ : LSTM \\\n",
        "https://yjjo.tistory.com/18 : GRU"
      ],
      "metadata": {
        "id": "oUp2TtBuarGs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Bidirectional => double weight\n",
        "import tensorflow as tf\n",
        "\n",
        "sentence = \"What time is it ?\"\n",
        "dic = {\n",
        "    \"is\": 0,\n",
        "    \"it\": 1,\n",
        "    \"What\": 2,\n",
        "    \"time\": 3,\n",
        "    \"?\": 4\n",
        "}\n",
        "\n",
        "sentence_tensor = tf.constant([[dic[word] for word in sentence.split()]])\n",
        "\n",
        "embedding_layer = tf.keras.layers.Embedding(input_dim=len(dic), output_dim=100)\n",
        "emb_out = embedding_layer(sentence_tensor)\n",
        "\n",
        "print(\"입력 문장 데이터 형태:\", emb_out.shape)\n",
        "\n",
        "bi_rnn = \\\n",
        "tf.keras.layers.Bidirectional(\n",
        "    tf.keras.layers.SimpleRNN(units=64, use_bias=False, return_sequences=True)\n",
        ")\n",
        "bi_out = bi_rnn(emb_out)\n",
        "\n",
        "print(\"Bidirectional RNN 결과 (최종 Step Output):\", bi_out.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X8nF3dSxW4j-",
        "outputId": "7ee54836-44a1-44e7-b9a7-93f60e81936e"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "입력 문장 데이터 형태: (1, 5, 100)\n",
            "Bidirectional RNN 결과 (최종 Step Output): (1, 5, 128)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "# 위 수식의 sigmoid 함수를 구현해 봅니다.\n",
        "def sigmoid(x):\n",
        "    return 1 / (1 + np.exp(-x))  \n",
        "\n",
        "\n",
        "# 단일 레이어 구현 함수\n",
        "def affine_layer_forward(X, W, b):\n",
        "    y = np.dot(X, W) + b\n",
        "    cache = (X, W, b)\n",
        "    return y, cache\n",
        "\n",
        "input_size = 784\n",
        "hidden_size = 50\n",
        "output_size = 10\n",
        "\n",
        "W1 = weight_init_std * np.random.randn(input_size, hidden_size)\n",
        "b1 = np.zeros(hidden_size)\n",
        "W2 = weight_init_std * np.random.randn(hidden_size, output_size)\n",
        "b2 = np.zeros(output_size)\n",
        "\n",
        "a1, cache1 = affine_layer_forward(X, W1, b1)\n",
        "z1 = sigmoid(a1)\n",
        "a2, cache2 = affine_layer_forward(z1, W2, b2)    # z1이 다시 두번째 레이어의 입력이 됩니다. \n",
        "\n",
        "print(a2[0])  # 최종 출력이 output_size만큼의 벡터가 되었습니다.\n",
        "\n",
        "def softmax(x):\n",
        "    if x.ndim == 2:\n",
        "        x = x.T\n",
        "        x = x - np.max(x, axis=0)\n",
        "        y = np.exp(x) / np.sum(np.exp(x), axis=0)\n",
        "        return y.T \n",
        "\n",
        "    x = x - np.max(x) # 오버플로 대책\n",
        "    return np.exp(x) / np.sum(np.exp(x))\n",
        "\n",
        "# 정답 라벨을 One-hot 인코딩하는 함수\n",
        "def _change_one_hot_label(X, num_category):\n",
        "    T = np.zeros((X.size, num_category))\n",
        "    for idx, row in enumerate(T):\n",
        "        row[X[idx]] = 1\n",
        "        \n",
        "    return T\n",
        "def cross_entropy_error(y, t):\n",
        "    if y.ndim == 1:\n",
        "        t = t.reshape(1, t.size)\n",
        "        y = y.reshape(1, y.size)\n",
        "        \n",
        "    # 훈련 데이터가 원-핫 벡터라면 정답 레이블의 인덱스로 반환\n",
        "    if t.size == y.size:\n",
        "        t = t.argmax(axis=1)\n",
        "             \n",
        "    batch_size = y.shape[0]\n",
        "    return -np.sum(np.log(y[np.arange(batch_size), t])) / batch_size\n",
        "\n",
        "learning_rate = 0.1\n",
        "\n",
        "def update_params(W1, b1, W2, b2, dW1, db1, dW2, db2, learning_rate):\n",
        "    W1 = W1 - learning_rate*dW1\n",
        "    b1 = b1 - learning_rate*db1\n",
        "    W2 = W2 - learning_rate*dW2\n",
        "    b2 = b2 - learning_rate*db2\n",
        "    return W1, b1, W2, b2\n",
        "\n"
      ],
      "metadata": {
        "id": "AJCVbLNqW5mB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "TvoY8uUNfxzP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "MJh1mp06f0dM"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}